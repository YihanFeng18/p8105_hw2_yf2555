Homework 2
================
Yihan Feng
9/27/2020

This is my solution to Homework 2

# Problem 1

## Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./dataset/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",     # only take the "Mr. Trash Wheel" sheet
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

## Read 2018 and 2017 precipitation data.

``` r
precip_2018 =
  read_xlsx(
    "./dataset/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1      # means skip the first row
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)
  

  precip_2017 =
  read_xlsx(
    "./dataset/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1      # means skip the first row
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

## Combine 2017 and 2018 annual precipitation.

``` r
month_df = tibble(
  month = 1:12,
  month_name = month.name
)

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # ... with 14 more rows

## Data description

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include monthly precipitation data.

The total precipitation data in 2018 is 70.33 inches. And the median
number of sports balls in a dumpster in 2017 is 2.145 inches.

# Problem 2

## Read and clean the NYC transit dataset.

``` r
transit_df = 
  read_csv("./dataset/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>% 
  mutate(entry = ifelse(entry == "YES", yes = TRUE, no = FALSE))
```

## Dataset description

This dataset contains information of transit system in New York City,
NY. The dataset contains information on line, station, routes’ name and
number, and ADA compliance. For dataset cleaning, I change variable
names to snake case, and then select interested variables. I also
convert the entry variable to a logical variable. The resulting dataset
has 1868 rows and 19 columns, yet this dataset is still not tidy enough
so far.

## Calculate number of distinct stations.

``` r
transit_distinct = distinct(transit_df, station_name, line)
```

There are 465 distinct stations.

## Calculate number of ADA compliant stations.

``` r
transit_ada = transit_df %>%
  filter(ada == "TRUE") %>%
  distinct(station_name, line)
```

There are 84 ADA compliant stations.

## Calculate proportion of station entrances/exits without vending.

``` r
transit_distinct_number = nrow(transit_distinct)

transit_vending = transit_df %>%
  filter(entry == "TRUE", vending == "NO") %>%
  distinct(station_name, line)
transit_vending_number = nrow(transit_vending)

transit_vending_prop = transit_vending_number/transit_distinct_number
```

There are 0.0924731 proportion of station entrances/exits without
vending.

## Reformat data so that route number and route name are distinct variables.

``` r
transit_reformat = transit_df %>%
  mutate_at(vars(route1 : route11), as.character)%>%
  pivot_longer(
    route1 : route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number") %>%
drop_na(route_number)
```

## Calculate number of distinct stations serve the A train

``` r
transit_atrain = transit_reformat %>%
  filter(route_number == "A") %>%
  distinct(station_name, line)
```

There are 60 stations serve the A train.

## Of the stations that serve the A train, calculate the number of ADA compliant.

``` r
transit_ada_atrain = transit_reformat %>%
  filter(route_number == "A", ada == "TRUE") %>%
  distinct(station_name, line)
```

There are 17 stations serve the A train with ADA compliant.

# Problem 3

## Read, clean and rearrange pols-month dataset.

``` r
pols_month_df = 
  read_csv("./dataset/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>%
  mutate(month = month.abb[as.numeric(month)],
         president = case_when(prez_gop == "1" ~ "gop", prez_dem == "1" ~ "dem")) %>%
  select(-c(prez_gop, prez_dem, day))
```

## Read, clean, and rearrange snp dataset.

``` r
snp_df = 
  read_csv("./dataset/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>%
  mutate(month = month.abb[as.numeric(month)]) %>%
  select(year, month, everything(), -c(day)) %>%
  arrange(year, month)
```

## Read, clean, and rearrange unemployment dataset.

``` r
unemploy_df =
  read_csv("./dataset/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan : dec,
    names_to = "month",
    values_to = "unemployment" 
  ) %>%
  mutate(month = month.abb[as.factor(month)],
         year = as.character(year)) %>%
  arrange(year, month)
```

## Merge the three datasets.

``` r
snp_pols = left_join(pols_month_df, snp_df, by = c("year", "month"))

snp_pols_unemploy = left_join(snp_pols, unemploy_df, by = c("year", "month"))
```

## Dataset summary and description.

The final dataset consists of “pols\_month\_df”, “snp\_df”, and
“unemploy\_df”. “pols\_month\_df” dataset contains information on
numbers of politicians in democratic and republican each month, and the
corresponding president’s party from 1947 to 2015. “snp\_df” dataset
contains information on the SNP closing index in selected months from
1950 to 2015. “unemploy\_df” dataset contains information on the
unemployment rate of selected months from 1948 to 2015.

The resulting merged dataset has 822 rows and 11 columns. It ranges from
year 1947 to year 2015. It includes some key variables from the three
individual datasets, the unemployment rate, SNP closing index, number of
politicians in each party, and their corresponding year and month.
